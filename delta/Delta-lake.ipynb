{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eeb9441-d2df-4781-8ae5-6b8a566f7504",
   "metadata": {},
   "source": [
    "<!-- Teste de Time Travel em Delta Lake -->\n",
    "# <font color='Red'>Delta Lake</font>\n",
    "## <font color='blue'>Manipulação de dados em Delta Lake</font>\n",
    "## <font color='blue'>Time Travel</font>\n",
    "### <font color='Green'>Data Lakehouse Time Travel com Apache Spark e Delta Lake</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11688e-292e-474f-8cc6-6859f793c33f",
   "metadata": {},
   "source": [
    "## Criando a Sessão Spark e a Tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c6d00f-b05e-4b9d-a043-b11340c28906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, to_json, lit, collect_list, size, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f365af55-d955-4786-9d93-7263b1d933ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SparkSession._instantiatedSession is not None:\n",
    "    SparkSession._instantiatedSession.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab0fc4d-de5d-4f74-a242-49bb858b5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do Spark com Delta Lake\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"deltalake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"5000\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ac0b49-a450-4242-979a-27db959e0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Djdk.internal.platform.cgroupv2.enable=false\n",
      "Picked up JAVA_TOOL_OPTIONS: -Djdk.internal.platform.cgroupv2.enable=false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-9f659548-9e4e-4f8e-b4fe-78315a63222b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.2.1 in central\n",
      "\tfound io.delta#delta-storage;3.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 74ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.1 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-9f659548-9e4e-4f8e-b4fe-78315a63222b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "25/03/22 19:53:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "    spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67298cc1-8f96-45fd-b2c4-6e7a2c40b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o nível de log\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63732e77-9284-4848-abbb-b444a4bf7c4a",
   "metadata": {},
   "source": [
    "A tabela Delta, usada no contexto do Delta Lake, é um tipo de tabela baseado no formato de armazenamento Delta, desenvolvido pela Databricks. Esse formato combina as vantagens dos Data Lakes (armazenamento escalável e econômico) com as funcionalidades tradicionais de um Data Warehouse (transações ACID, versionamento e consultas rápidas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6686183e-7a32-44d4-9f34-7a98bbb20069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho da tabela Delta\n",
    "delta_table_path = \"/repositorio/delta-table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639d14b-f657-4748-bda5-0809f4597291",
   "metadata": {},
   "source": [
    "## Armazenamento Inicial no Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f319d0-a82a-4bfb-ba5c-6ff2d102e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome do arquivo\n",
    "csv_file_path = \"dados_iniciais.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4ce8d4a-77fb-46aa-b5cf-b7a7aaa418f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados iniciais do arquivo CSV...\n"
     ]
    }
   ],
   "source": [
    "# Ler os dados do arquivo CSV para um DataFrame\n",
    "print(\"Carregando dados iniciais do arquivo CSV...\")\n",
    "sil_dados = spark.read.csv(csv_file_path, header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f07c9dd-13b6-46c6-8485-cb47fa8ebe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravar dados na tabela Delta\n",
    "sil_dados.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34efcba9-2e79-46fc-9061-f95aee480ccd",
   "metadata": {},
   "source": [
    "## Manipulando os Dados no Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262328bd-34c2-4e3d-87ae-160a9d72d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados iniciais:\n",
      "+---+--------+-----+-------------------+\n",
      "| id|    nome|idade|             funcao|\n",
      "+---+--------+-----+-------------------+\n",
      "|  1|   Lucas|   30| Cientista de Dados|\n",
      "|  2|   Bruno|   18|  Analista de Dados|\n",
      "|  3| Mariana|   35| Arquiteto de Dados|\n",
      "|  4|Fernando|   40|Engenheiro de Dados|\n",
      "|  5| Gabriel|   28|   Engenheiro de IA|\n",
      "|  6|  Camila|   50|   Engenheiro de ML|\n",
      "|  7|  Amanda|   29| Engenheiro DataOps|\n",
      "|  8| Juliano|   43| Arquiteto de Dados|\n",
      "|  9| Gustavo|   56| Arquiteto de Dados|\n",
      "| 10| Vanessa|   31|  Analista de Dados|\n",
      "+---+--------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Leitura dos dados\n",
    "print(\"Dados iniciais:\")\n",
    "spark.read.format(\"delta\").load(delta_table_path).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28b44f6-ee7d-4422-baf3-932f4f71ec1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após atualização de Lucas:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|2  |Bruno   |18   |Analista de Dados      |\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|5  |Gabriel |28   |Engenheiro de IA       |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps     |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Atualizando idade e função de um funcionário\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "delta_table.update(\n",
    "    condition = \"nome = 'Lucas'\",\n",
    "    set = {\"idade\": \"32\", \"funcao\": \"'Gerente de Data Science'\"}\n",
    ")\n",
    "print(\"Após atualização de Lucas:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e84bfd-3050-465c-bd3b-2263407764ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após remoção de funcionários com idade <= 30:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Removendo registros com idade menor ou igual a 30\n",
    "delta_table.delete(condition = \"idade <= 30\")\n",
    "print(\"Após remoção de funcionários com idade <= 30:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e66065-b789-4bc1-a684-db04a3c3e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após inserção de novos registros:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inserindo múltiplos novos registros\n",
    "new_employees = spark.createDataFrame([\n",
    "    (11, \"Leonardo\", 27, \"Analytics Engineer\"),\n",
    "    (12, \"Felipe\", 31, \"Analytics Engineer\"),\n",
    "    (13, \"Paula\", 26, \"Engenheiro de Dados\"),\n",
    "    (14, \"Melissa\", 26, \"Cientista de Dados\")\n",
    "], [\"id\", \"nome\", \"idade\", \"funcao\"])\n",
    "\n",
    "delta_table.alias(\"existingData\").merge(\n",
    "    new_employees.alias(\"newData\"),\n",
    "    \"existingData.id = newData.id\"\n",
    ").whenNotMatchedInsertAll().execute()\n",
    "\n",
    "print(\"Após inserção de novos registros:\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2776c2c-524c-41f3-820b-e906cea60750",
   "metadata": {},
   "source": [
    "## UPSERT - Inserir ou Atualizar (Merge) Dados Existentes e Novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463f7e5a-6626-4b86-a6c4-56dbac77670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após upsert (atualização/inserção):\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |36   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|15 |Tales   |24   |Arquiteto RPA          |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UPSERT - Inserir ou Atualizar (Merge) dados existentes e novos\n",
    "upsert_data = spark.createDataFrame([\n",
    "    (3, \"Mariana\", 36, \"Arquiteto de Dados\"),  # Atualizar idade da Mariana\n",
    "    (15, \"Tales\", 24, \"Arquiteto RPA\")         # Novo registro\n",
    "], [\"id\", \"nome\", \"idade\", \"funcao\"])\n",
    "\n",
    "delta_table.alias(\"oldData\").merge(\n",
    "    upsert_data.alias(\"upsertData\"),\n",
    "    \"oldData.id = upsertData.id\"\n",
    ").whenMatchedUpdate(set={\n",
    "    \"idade\": \"upsertData.idade\",\n",
    "    \"funcao\": \"upsertData.funcao\"\n",
    "}).whenNotMatchedInsertAll().execute()\n",
    "\n",
    "print(\"Após upsert (atualização/inserção):\")\n",
    "delta_table.toDF().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af4833-7a1a-49a3-88ee-03389abdfd72",
   "metadata": {},
   "source": [
    "## Histórico de Alterações (Time Travel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28332cb0-b6d4-4c62-83d0-77a63f4a4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela tem 5 versões.\n"
     ]
    }
   ],
   "source": [
    "# Caminho para a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Obter o histórico completo\n",
    "history_df = delta_table.history()\n",
    "\n",
    "# Contar o número de versões\n",
    "num_versions = history_df.count()\n",
    "print(f\"A tabela tem {num_versions} versões.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b81ba7-ff44-4604-8460-06f777184595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão inicial da tabela:\n",
      "+---+--------+-----+-------------------+\n",
      "|id |nome    |idade|funcao             |\n",
      "+---+--------+-----+-------------------+\n",
      "|1  |Lucas   |30   |Cientista de Dados |\n",
      "|2  |Bruno   |18   |Analista de Dados  |\n",
      "|3  |Mariana |35   |Arquiteto de Dados |\n",
      "|4  |Fernando|40   |Engenheiro de Dados|\n",
      "|5  |Gabriel |28   |Engenheiro de IA   |\n",
      "|6  |Camila  |50   |Engenheiro de ML   |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps |\n",
      "|8  |Juliano |43   |Arquiteto de Dados |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados |\n",
      "|10 |Vanessa |31   |Analista de Dados  |\n",
      "+---+--------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Acessar a versão mais antiga da tabela (versão 0)\n",
    "print(\"Versão inicial da tabela:\")\n",
    "old_version = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "old_version.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc4baac-e1fa-4c5c-ad35-f7e342dcf569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão 0 da tabela:\n",
      "+---+--------+-----+-------------------+\n",
      "|id |nome    |idade|funcao             |\n",
      "+---+--------+-----+-------------------+\n",
      "|1  |Lucas   |30   |Cientista de Dados |\n",
      "|2  |Bruno   |18   |Analista de Dados  |\n",
      "|3  |Mariana |35   |Arquiteto de Dados |\n",
      "|4  |Fernando|40   |Engenheiro de Dados|\n",
      "|5  |Gabriel |28   |Engenheiro de IA   |\n",
      "|6  |Camila  |50   |Engenheiro de ML   |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps |\n",
      "|8  |Juliano |43   |Arquiteto de Dados |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados |\n",
      "|10 |Vanessa |31   |Analista de Dados  |\n",
      "+---+--------+-----+-------------------+\n",
      "\n",
      "Versão 1 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|2  |Bruno   |18   |Analista de Dados      |\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|5  |Gabriel |28   |Engenheiro de IA       |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps     |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 4 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |36   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|15 |Tales   |24   |Arquiteto RPA          |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Versão 0 da tabela:\")\n",
    "version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "version_0.show(truncate=False)\n",
    "\n",
    "print(\"Versão 1 da tabela:\")\n",
    "version_1 = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(delta_table_path)\n",
    "version_1.show(truncate=False)\n",
    "\n",
    "print(\"Versão 4 da tabela:\")\n",
    "version_4 = spark.read.format(\"delta\").option(\"versionAsOf\", 4).load(delta_table_path)\n",
    "version_4.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b001a2-9ff0-4240-b036-a9716b3d230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar uma coluna que identifica a versão\n",
    "version_0 = version_0.withColumn(\"versao\", lit(0))\n",
    "version_4 = version_4.withColumn(\"versao\", lit(4))\n",
    "\n",
    "# Unir as duas versões\n",
    "changes = version_0.union(version_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3b6d58a-8fda-47e7-974f-4044f7e27173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alterações entre versões:\n",
      "+---+--------+-------+\n",
      "|id |nome    |versoes|\n",
      "+---+--------+-------+\n",
      "|7  |Amanda  |[0]    |\n",
      "|5  |Gabriel |[0]    |\n",
      "|2  |Bruno   |[0]    |\n",
      "|15 |Tales   |[4]    |\n",
      "|11 |Leonardo|[4]    |\n",
      "|14 |Melissa |[4]    |\n",
      "|12 |Felipe  |[4]    |\n",
      "|13 |Paula   |[4]    |\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as diferenças em relação ao nome\n",
    "print(\"Alterações entre versões:\")\n",
    "changes.groupBy(\"id\", \"nome\") \\\n",
    "       .agg(collect_list(\"versao\").alias(\"versoes\")) \\\n",
    "       .filter(size(\"versoes\") == 1) \\\n",
    "       .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a4787fe-0ee4-4f61-93e0-3ae178ac8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alterações entre versões:\n",
      "+---+-----+-------+\n",
      "|id |idade|versoes|\n",
      "+---+-----+-------+\n",
      "|5  |28   |[0]    |\n",
      "|3  |35   |[0]    |\n",
      "|2  |18   |[0]    |\n",
      "|1  |30   |[0]    |\n",
      "|7  |29   |[0]    |\n",
      "|15 |24   |[4]    |\n",
      "|1  |32   |[4]    |\n",
      "|3  |36   |[4]    |\n",
      "|11 |27   |[4]    |\n",
      "|14 |26   |[4]    |\n",
      "|12 |31   |[4]    |\n",
      "|13 |26   |[4]    |\n",
      "+---+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as diferenças em relação a idade\n",
    "print(\"Alterações entre versões:\")\n",
    "changes.groupBy(\"id\", \"idade\") \\\n",
    "       .agg(collect_list(\"versao\").alias(\"versoes\")) \\\n",
    "       .filter(size(\"versoes\") == 1) \\\n",
    "       .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1818e37-0f5b-40d9-965a-98f48eb3af48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferença de média de idade entre versões:\n",
      "+------+------------------+\n",
      "|versao|       media_idade|\n",
      "+------+------------------+\n",
      "|     0|              36.0|\n",
      "|     4|35.166666666666664|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcular a média de idade por versão\n",
    "avg_ages = version_0.union(version_4) \\\n",
    "    .groupBy(\"versao\") \\\n",
    "    .agg(avg(\"idade\").alias(\"media_idade\"))\n",
    "\n",
    "# Mostrar a diferença de média de idade entre as versões\n",
    "print(\"Diferença de média de idade entre versões:\")\n",
    "avg_ages.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f8543f7-4579-465c-91b2-cf1c7a9f7bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico de alterações da tabela Delta (formatado):\n",
      "+------+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|Versão|Operação|Métricas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |Metadados do Usuário|\n",
      "+------+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|4     |MERGE   |{numTargetRowsCopied -> 6, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1478, numTargetBytesRemoved -> 1444, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 656, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 310, numTargetRowsUpdated -> 1, numOutputRows -> 8, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 2, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 209}|NULL                |\n",
      "|3     |MERGE   |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetBytesAdded -> 5079, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 587, numTargetRowsInserted -> 4, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 0, numTargetRowsUpdated -> 0, numOutputRows -> 4, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 583}     |NULL                |\n",
      "|2     |DELETE  |{numRemovedFiles -> 1, numRemovedBytes -> 1517, numCopiedRows -> 7, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 276, numDeletionVectorsUpdated -> 0, numDeletedRows -> 3, scanTimeMs -> 172, numAddedFiles -> 1, numAddedBytes -> 1444, rewriteTimeMs -> 103}                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "|1     |UPDATE  |{numRemovedFiles -> 1, numRemovedBytes -> 1491, numCopiedRows -> 9, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 559, numDeletionVectorsUpdated -> 0, scanTimeMs -> 386, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1517, rewriteTimeMs -> 171}                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "|0     |WRITE   |{numFiles -> 1, numOutputRows -> 10, numOutputBytes -> 1491}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "+------+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega a tabela delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Carregar o histórico de alterações da tabela Delta\n",
    "history = delta_table.history()\n",
    "\n",
    "# Selecionar apenas as colunas relevantes\n",
    "formatted_history = history.select(\n",
    "    col(\"version\").alias(\"Versão\"),\n",
    "    col(\"operation\").alias(\"Operação\"),\n",
    "    col(\"operationMetrics\").alias(\"Métricas\"),\n",
    "    col(\"userMetadata\").alias(\"Metadados do Usuário\")\n",
    ")\n",
    "\n",
    "# Mostrar as alterações \n",
    "print(\"Histórico de alterações da tabela Delta (formatado):\")\n",
    "formatted_history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9f2ac6c-884f-4e84-ac21-daac0571fe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|Versão|Operação|Métricas                                                                                                                                                                                                                                                                                                                    |Metadados do Usuário|\n",
      "+------+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|1     |UPDATE  |{numRemovedFiles -> 1, numRemovedBytes -> 1491, numCopiedRows -> 9, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 559, numDeletionVectorsUpdated -> 0, scanTimeMs -> 386, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1517, rewriteTimeMs -> 171}|NULL                |\n",
      "+------+--------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se você quiser exibir apenas operações específicas (por exemplo, UPDATE), pode usar .filter():\n",
    "filtered_history = formatted_history.filter(col(\"Operação\") == \"UPDATE\")\n",
    "filtered_history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64e8a148-0c1f-489a-9a46-60757e6b7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico salvo em: output\n"
     ]
    }
   ],
   "source": [
    "# Carregar o histórico de alterações da tabela Delta\n",
    "history = delta_table.history()\n",
    "\n",
    "# Selecionar e formatar as colunas\n",
    "formatted_history = history.select(\n",
    "    col(\"version\").alias(\"Versão\"),\n",
    "    col(\"operation\").alias(\"Operação\"),\n",
    "    to_json(col(\"operationMetrics\")).alias(\"Métricas\"),  # Converter MAP para JSON, para conseguir salvar em CSV\n",
    "    col(\"userMetadata\").alias(\"Metadados do Usuário\")\n",
    ")\n",
    "\n",
    "# Salvar o histórico formatado em CSV\n",
    "output_path = \"output\"\n",
    "formatted_history.write.format(\"csv\").option(\"header\", \"true\").save(output_path)\n",
    "\n",
    "print(f\"Histórico salvo em: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cabbc2-9079-4dcc-af2a-1967de7dee21",
   "metadata": {},
   "source": [
    "Embora não haja um comando direto de rollback no Delta Lake, você pode sobrescrever uma nova versão com os dados de uma versão anterior sem perder todo o histórico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef8d77f-074d-4652-9a6c-39c4c9b72b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Consultar uma versão antiga (versão 2)\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2adfe83d-b445-4265-b6a6-7c0f3fe3f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a versão 2\n",
    "old_version = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a9b773-de7e-49a3-b8dd-9a945d487445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobrescrever a tabela principal com a versão 2\n",
    "# Isso vai gerar uma cópia da versão 2 que será agora a versão principal. \n",
    "old_version.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ffb26bf-ee6d-4e89-bfec-e8047cee4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar os dados sobrescritos\n",
    "spark.read.format(\"delta\").load(delta_table_path).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d72eca9a-eb03-4d03-ab1e-16feb8893a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela tem 6 versões.\n"
     ]
    }
   ],
   "source": [
    "# Caminho para a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Obter o histórico completo\n",
    "history_df = delta_table.history()\n",
    "\n",
    "# Contar o número de versões\n",
    "num_versions = history_df.count()\n",
    "print(f\"A tabela tem {num_versions} versões.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a248d2fb-acc1-44d9-b8cf-4d1066692742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão 0 da tabela:\n",
      "+---+--------+-----+-------------------+\n",
      "|id |nome    |idade|funcao             |\n",
      "+---+--------+-----+-------------------+\n",
      "|1  |Lucas   |30   |Cientista de Dados |\n",
      "|2  |Bruno   |18   |Analista de Dados  |\n",
      "|3  |Mariana |35   |Arquiteto de Dados |\n",
      "|4  |Fernando|40   |Engenheiro de Dados|\n",
      "|5  |Gabriel |28   |Engenheiro de IA   |\n",
      "|6  |Camila  |50   |Engenheiro de ML   |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps |\n",
      "|8  |Juliano |43   |Arquiteto de Dados |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados |\n",
      "|10 |Vanessa |31   |Analista de Dados  |\n",
      "+---+--------+-----+-------------------+\n",
      "\n",
      "Versão 1 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|2  |Bruno   |18   |Analista de Dados      |\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|5  |Gabriel |28   |Engenheiro de IA       |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|7  |Amanda  |29   |Engenheiro DataOps     |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 2 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 3 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 4 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |36   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|15 |Tales   |24   |Arquiteto RPA          |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 5 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Versão 0 da tabela:\")\n",
    "version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "version_0.show(truncate=False)\n",
    "\n",
    "print(\"Versão 1 da tabela:\")\n",
    "version_1 = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(delta_table_path)\n",
    "version_1.show(truncate=False)\n",
    "\n",
    "print(\"Versão 2 da tabela:\")\n",
    "version_2 = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path)\n",
    "version_2.show(truncate=False)\n",
    "\n",
    "print(\"Versão 3 da tabela:\")\n",
    "version_3 = spark.read.format(\"delta\").option(\"versionAsOf\", 3).load(delta_table_path)\n",
    "version_3.show(truncate=False)\n",
    "\n",
    "print(\"Versão 4 da tabela:\")\n",
    "version_4 = spark.read.format(\"delta\").option(\"versionAsOf\", 4).load(delta_table_path)\n",
    "version_4.show(truncate=False)\n",
    "\n",
    "print(\"Versão 5 da tabela:\")\n",
    "version_5 = spark.read.format(\"delta\").option(\"versionAsOf\", 5).load(delta_table_path)\n",
    "version_5.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c630fa-769a-4848-bb1f-ba74f9b23bc3",
   "metadata": {},
   "source": [
    "Considerações:\n",
    "\n",
    "- A operação de sobrescrita cria uma nova versão na tabela Delta. Dados atuais ainda estarão no histórico, mas os dados sobrescritos substituem a visão principal da tabela.\n",
    "\n",
    "- Certifique-se de que o esquema da versão antiga é compatível com o esquema atual. Caso contrário, pode ser necessário habilitar a opção overwriteSchema.\n",
    "\n",
    "- Em ambientes críticos, prefira corrigir os dados com operações como MERGE ou UPDATE em vez de sobrescrever diretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83dc7b4-990a-40ad-9967-b9a33be04409",
   "metadata": {},
   "source": [
    "## Aplicando o VACUUM\n",
    "\n",
    "Por padrão, o Delta Lake impõe uma retenção mínima de 7 dias para garantir que operações como time travel ainda sejam possíveis e para evitar exclusão acidental de dados necessários para transações. Se você quiser reduzir esse período, será necessário modificar a configuração de retenção mínima.\n",
    "\n",
    "Você não poderá acessar versões anteriores além do período de retenção configurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa4a2707-aa84-4bd2-bf6c-4671241e070b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desativar temporariamente a proteção para retenção mínima\n",
    "spark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled = false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaabe9c2-cb20-4d01-b348-8998b8e3e507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando vacuum com retenção de 1 dia...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 4 files and directories in a total of 1 directories.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executar VACUUM com retenção de 1 dia\n",
    "print(\"Executando vacuum com retenção de 1 dia...\")\n",
    "delta_table.vacuum(retentionHours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8227021b-1148-41d4-bfec-d0d2ad839cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela tem 10 versões.\n"
     ]
    }
   ],
   "source": [
    "# Caminho para a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Obter o histórico completo\n",
    "history_df = delta_table.history()\n",
    "\n",
    "# Contar o número de versões\n",
    "num_versions = history_df.count()\n",
    "print(f\"A tabela tem {num_versions} versões.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acd82d32-4185-4a72-af49-2c37cbc387bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histórico de alterações da tabela Delta (formatado):\n",
      "+------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|Versão|Operação    |Métricas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |Metadados do Usuário|\n",
      "+------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|9     |VACUUM END  |{numDeletedFiles -> 4, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL                |\n",
      "|8     |VACUUM START|{numFilesToDelete -> 4, sizeOfDataToDelete -> 4999}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL                |\n",
      "|7     |VACUUM END  |{numDeletedFiles -> 0, numVacuumedDirectories -> 1}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL                |\n",
      "|6     |VACUUM START|{numFilesToDelete -> 0, sizeOfDataToDelete -> 0}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |NULL                |\n",
      "|5     |WRITE       |{numFiles -> 1, numOutputRows -> 7, numOutputBytes -> 1444}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |NULL                |\n",
      "|4     |MERGE       |{numTargetRowsCopied -> 6, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1478, numTargetBytesRemoved -> 1444, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 656, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 310, numTargetRowsUpdated -> 1, numOutputRows -> 8, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 2, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 209}|NULL                |\n",
      "|3     |MERGE       |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetBytesAdded -> 5079, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 587, numTargetRowsInserted -> 4, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 0, numTargetRowsUpdated -> 0, numOutputRows -> 4, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 583}     |NULL                |\n",
      "|2     |DELETE      |{numRemovedFiles -> 1, numRemovedBytes -> 1517, numCopiedRows -> 7, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 276, numDeletionVectorsUpdated -> 0, numDeletedRows -> 3, scanTimeMs -> 172, numAddedFiles -> 1, numAddedBytes -> 1444, rewriteTimeMs -> 103}                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "|1     |UPDATE      |{numRemovedFiles -> 1, numRemovedBytes -> 1491, numCopiedRows -> 9, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 559, numDeletionVectorsUpdated -> 0, scanTimeMs -> 386, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 1517, rewriteTimeMs -> 171}                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "|0     |WRITE       |{numFiles -> 1, numOutputRows -> 10, numOutputBytes -> 1491}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |NULL                |\n",
      "+------+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carrega a tabela delta\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Carregar o histórico de alterações da tabela Delta\n",
    "history = delta_table.history()\n",
    "\n",
    "# Selecionar apenas as colunas relevantes\n",
    "formatted_history = history.select(\n",
    "    col(\"version\").alias(\"Versão\"),\n",
    "    col(\"operation\").alias(\"Operação\"),\n",
    "    col(\"operationMetrics\").alias(\"Métricas\"),\n",
    "    col(\"userMetadata\").alias(\"Metadados do Usuário\")\n",
    ")\n",
    "\n",
    "# Mostrar as alterações \n",
    "print(\"Histórico de alterações da tabela Delta (formatado):\")\n",
    "formatted_history.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d16326ab-da2b-47c8-9a80-ca10dfece7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão 4 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |36   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "|15 |Tales   |24   |Arquiteto RPA          |\n",
      "|11 |Leonardo|27   |Analytics Engineer     |\n",
      "|14 |Melissa |26   |Cientista de Dados     |\n",
      "|12 |Felipe  |31   |Analytics Engineer     |\n",
      "|13 |Paula   |26   |Engenheiro de Dados    |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 5 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 6 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 7 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n",
      "Versão 9 da tabela:\n",
      "+---+--------+-----+-----------------------+\n",
      "|id |nome    |idade|funcao                 |\n",
      "+---+--------+-----+-----------------------+\n",
      "|1  |Lucas   |32   |Gerente de Data Science|\n",
      "|3  |Mariana |35   |Arquiteto de Dados     |\n",
      "|4  |Fernando|40   |Engenheiro de Dados    |\n",
      "|6  |Camila  |50   |Engenheiro de ML       |\n",
      "|8  |Juliano |43   |Arquiteto de Dados     |\n",
      "|9  |Gustavo |56   |Arquiteto de Dados     |\n",
      "|10 |Vanessa |31   |Analista de Dados      |\n",
      "+---+--------+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''print(\"Versão 0 da tabela:\")\n",
    "version_0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "version_0.show(truncate=False)\n",
    "\n",
    "print(\"Versão 1 da tabela:\")\n",
    "version_1 = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(delta_table_path)\n",
    "version_1.show(truncate=False)\n",
    "\n",
    "print(\"Versão 2 da tabela:\")\n",
    "version_2 = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(delta_table_path)\n",
    "version_2.show(truncate=False)\n",
    "\n",
    "print(\"Versão 3 da tabela:\")\n",
    "version_3 = spark.read.format(\"delta\").option(\"versionAsOf\", 3).load(delta_table_path)\n",
    "version_3.show(truncate=False)'''\n",
    "\n",
    "print(\"Versão 4 da tabela:\")\n",
    "version_4 = spark.read.format(\"delta\").option(\"versionAsOf\", 4).load(delta_table_path)\n",
    "version_4.show(truncate=False)\n",
    "\n",
    "print(\"Versão 5 da tabela:\")\n",
    "version_5 = spark.read.format(\"delta\").option(\"versionAsOf\", 5).load(delta_table_path)\n",
    "version_5.show(truncate=False)\n",
    "\n",
    "print(\"Versão 6 da tabela:\")\n",
    "version_6 = spark.read.format(\"delta\").option(\"versionAsOf\", 6).load(delta_table_path)\n",
    "version_6.show(truncate=False)\n",
    "\n",
    "print(\"Versão 7 da tabela:\")\n",
    "version_7 = spark.read.format(\"delta\").option(\"versionAsOf\", 7).load(delta_table_path)\n",
    "version_7.show(truncate=False)\n",
    "\n",
    "print(\"Versão 9 da tabela:\")\n",
    "version_9 = spark.read.format(\"delta\").option(\"versionAsOf\", 9).load(delta_table_path)\n",
    "version_9.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2a33278-067e-48c6-a1c0-12398acb1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reativar a proteção para retenção mínima\n",
    "spark.sql(\"SET spark.databricks.delta.retentionDurationCheck.enabled = true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71728fff-cf08-475d-8324-c0dca783c0e8",
   "metadata": {},
   "source": [
    "Se o VACUUM foi executado com um período curto de retenção, versões mais antigas podem ter sido excluídas e não estarão disponíveis no histórico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c717b208-85de-4a15-b297-ae607f5f11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaliza a sessão Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892408a-a8a2-4197-83d5-e8bccb618f33",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
